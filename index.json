[{"authors":["debora_nozza"],"categories":null,"content":"Debora Nozza is an Assistant Professor in Computing Sciences at Bocconi University. She was awarded a €120,000 grant from Fondazione Cariplo for her project MONICA, which focuses on monitoring coverage, attitudes, and accessibility of Italian measures in response to COVID-19. Her research interests mainly focus on Natural Language Processing, specifically on the detection and counter-acting of hate speech and algorithmic bias on Social Media data in multilingual context.\nShe organized the 7th Workshop on Online Abuse and Harms (WOAH) at ACL 2023 and the ICWSM 2023 Data Challenge: Temporal social data at ICWSM 2023. She was one of the organizers of the task on Automatic Misogyny Identification (AMI) at Evalita 2018 and Evalita 2020, and one of the organizers of the HatEval Task 5 at SemEval 2019 on multilingual detection of hate speech against immigrants and women in Twitter.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"32fa56661196e9ad30989f2f33db55f9","permalink":"https://deboranozza.com/authors/debora/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/debora/","section":"authors","summary":"Debora Nozza is an Assistant Professor in Computing Sciences at Bocconi University. She was awarded a €120,000 grant from Fondazione Cariplo for her project MONICA, which focuses on monitoring coverage, attitudes, and accessibility of Italian measures in response to COVID-19. Her research interests mainly focus on Natural Language Processing, specifically on the detection and counter-acting of hate speech and algorithmic bias on Social Media data in multilingual context.\nShe organized the 7th Workshop on Online Abuse and Harms (WOAH) at ACL 2023 and the ICWSM 2023 Data Challenge: Temporal social data at ICWSM 2023.","tags":null,"title":"Debora Nozza","type":"authors"},{"authors":["Gabriele Ruggeri","Debora Nozza"],"categories":[],"content":"","date":1689120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689120000,"objectID":"63001a4b70ad72b7258ca6178b221fa1","permalink":"https://deboranozza.com/publication/2023-multidimensional-bias-vision-language-models/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2023-multidimensional-bias-vision-language-models/","section":"publication","summary":"In recent years, joint Vision-Language (VL) models have increased in popularity and capability. Very few studies have attempted to investigate bias in VL models, even though it is a well-known issue in both individual modalities.This paper presents the first multi-dimensional analysis of bias in English VL models, focusing on gender, ethnicity, and age as dimensions.When subjects are input as images, pre-trained VL models complete a neutral template with a hurtful word 5% of the time, with higher percentages for female and young subjects.Bias presence in downstream models has been tested on Visual Question Answering. We developed a novel bias metric called the Vision-Language Association Test based on questions designed to elicit biased associations between stereotypical concepts and targets. Our findings demonstrate that pre-trained VL models contain biases that are perpetuated in downstream tasks.","tags":["Fairness","NLP","multimodal"],"title":"A Multi-dimensional study on Bias in Vision-Language models","type":"publication"},{"authors":["Amanda Cercas Curry","Giuseppe Attanasio","Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1689120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689120000,"objectID":"f06c4346370b070a759172242d7d10a1","permalink":"https://deboranozza.com/publication/2023-milanlp-semeval-2023-task-10-ensembling-domain-adapted-regularized-pretrained-language-models-robust-sexism-detection/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2023-milanlp-semeval-2023-task-10-ensembling-domain-adapted-regularized-pretrained-language-models-robust-sexism-detection/","section":"publication","summary":"We present the system proposed by the MilaNLP team for the Explainable Detection of Online Sexism (EDOS) shared task. We propose an ensemble modeling approach to combine different classifiers trained with domain adaptation objectives and standard fine-tuning.Our results show that the ensemble is more robust than individual models and that regularized models generate more “conservative” predictions, mitigating the effects of lexical overfitting.However, our error analysis also finds that many of the misclassified instances are debatable, raising questions about the objective annotatability of hate speech data.","tags":["Hate Speech","NLP","domain adaptation","language models"],"title":"MilaNLP at SemEval-2023 Task 10: Ensembling Domain-Adapted and Regularized Pretrained Language Models for Robust Sexism Detection","type":"publication"},{"authors":["Flor Miriam Plaza-del-Arco","Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1689120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689120000,"objectID":"3f2cc27a6d89ea664c434ace9993294a","permalink":"https://deboranozza.com/publication/2023-zero-shot-prompting-hate-speech/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2023-zero-shot-prompting-hate-speech/","section":"publication","summary":"Hate speech detection faces two significant challenges: 1) the limited availability of labeled data and 2) the high variability of hate speech across different contexts and languages. Prompting brings a ray of hope to these challenges. It allows injecting a model with task-specific knowledge without relying on labeled data. This paper explores zero-shot learning with prompting for hate speech detection. We investigate how well zero-shot learning can detect hate speech in 3 languages with limited labeled data. We experiment with various large language models and verbalizers on 8 benchmark datasets. Our findings highlight the impact of prompt selection on the results. They also suggest that prompting, specifically with recent large language models, can achieve performance comparable to and surpass fine-tuned models, making it a promising alternative for under-resourced languages. Our findings highlight the potential of prompting for hate speech detection and show how both the prompt and the model have a significant impact on achieving more accurate predictions in this task.","tags":["Hate Speech","NLP","multilingual"],"title":"Respectful or Toxic? Using Zero-Shot Learning with Language Models to Detect Hate Speech","type":"publication"},{"authors":["Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1689120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689120000,"objectID":"1ebebe2dde0f3ca3bcb2976010570452","permalink":"https://deboranozza.com/publication/2023-prof-profanity-obfuscation-nlp/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2023-prof-profanity-obfuscation-nlp/","section":"publication","summary":"Work on hate speech has made considering rude and harmful examples in scientific publications inevitable. This situation raises various problems, such as whether or not to obscure profanities. While science must accurately disclose what it does, the unwarranted spread of hate speech can harm readers and increases its internet frequency. While maintaining publications’ professional appearance, obfuscating profanities makes it challenging to evaluate the content, especially for non-native speakers. Surveying 150 ACL papers, we discovered that obfuscation is usually used for English but not other languages, and even then, quite unevenly. We discuss the problems with obfuscation and suggest a multilingual community resource called PrOf with a Python module to standardize profanity obfuscation processes. We believe PrOf can help scientific publication policies to make hate speech work accessible and comparable, irrespective of language.","tags":["Hate Speech","NLP","multilingual"],"title":"The State of Profanity Obfuscation in Natural Language Processing Scientific Publications","type":"publication"},{"authors":["Anne Lauscher","Debora Nozza","Ehm Miltersen","Archie Crowley","Dirk Hovy"],"categories":[],"content":"","date":1689120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689120000,"objectID":"ff9d8520053fa8f944c7faa36dfc35da","permalink":"https://deboranozza.com/publication/2023-commercial-machine-translation-fail-neopronouns/","publishdate":"2023-07-12T14:48:20+01:00","relpermalink":"/publication/2023-commercial-machine-translation-fail-neopronouns/","section":"publication","summary":"As 3rd-person pronoun usage shifts to include novel forms, e.g., neopronouns, we need more research on identity-inclusive NLP. Exclusion is particularly harmful in one of the most popular NLP applications, machine translation (MT). Wrong pronoun translations can discriminate against marginalized groups, e.g., non-binary individuals (Dev et al., 2021). In this “reality check”, we study how three commercial MT systems translate 3rd-person pronouns. Concretely, we compare the translations of gendered vs. gender-neutral pronouns from English to five other languages (Danish, Farsi, French, German, Italian), and vice versa, from Danish to English.Our error analysis shows that the presence of a gender-neutral pronoun often leads to grammatical and semantic translation errors. Similarly, gender neutrality is often not preserved. By surveying the opinions of affected native speakers from diverse languages, we provide recommendations to address the issue in future MT research.","tags":["NLP","pronouns","fairness","ethics"],"title":"What about ''em''? How Commercial Machine Translation Fails to Handle (Neo-)Pronouns","type":"publication"},{"authors":["Davide Locatelli","Greta Damo","Debora Nozza"],"categories":[],"content":"","date":1683849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683849600,"objectID":"51e9a40f92fa680cf8527ec7904a72b4","permalink":"https://deboranozza.com/publication/2023-cross-lingual-study-homotransphobia/","publishdate":"2023-05-12T14:48:20+01:00","relpermalink":"/publication/2023-cross-lingual-study-homotransphobia/","section":"publication","summary":"We present a cross-lingual study of homotransphobia on Twitter, examining the prevalence and forms of homotransphobic content in tweets related to LGBT issues in seven languages. Our findings reveal that homotransphobia is a global problem that takes on distinct cultural expressions, influenced by factors such as misinformation, cultural prejudices, and religious beliefs. To aid the detection of hate speech, we also devise a taxonomy that classifies public discourse around LGBT issues. By contributing to the growing body of research on online hate speech, our study provides valuable insights for creating effective strategies to combat homotransphobia on social media.","tags":["Hate Speech","NLP","multilingual"],"title":"A Cross-Lingual Study of Homotransphobia on Twitter","type":"publication"},{"authors":["Federico Bianchi","Pratyusha Kalluri","Esin Durmus","Faisal Ladhak","Myra Cheng","Debora Nozza","Tatsunori Hashimoto","Dan Jurafsky","James Zou","Aylin Caliskan"],"categories":[],"content":"","date":1683417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683417600,"objectID":"7483eea9fc94959cf7db5c17264fa5e3","permalink":"https://deboranozza.com/publication/2023-text-to-image-stereotypes/","publishdate":"2023-05-07T14:48:20+01:00","relpermalink":"/publication/2023-text-to-image-stereotypes/","section":"publication","summary":"Machine learning models are now able to convert user-written text descriptions into naturalistic images. These models are available to anyone online and are being used to generate millions of images a day. We investigate these models and find that they amplify dangerous and complex stereotypes. Moreover, we find that the amplified stereotypes are difficult to predict and not easily mitigated by users or model owners. The extent to which these image-generation models perpetuate and amplify stereotypes and their mass deployment is cause for serious concern.","tags":["Vision","NLP","Bias","Fairness"],"title":"Easily Accessible Text-to-Image Generation Amplifies Demographic Stereotypes at Large Scale","type":"publication"},{"authors":["Giuseppe Attanasio","Eliana Pastor","Chiara Di Bonaventura","Debora Nozza"],"categories":[],"content":"","date":1682985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682985600,"objectID":"32074e80da1ca4ed7fe78f30fa8cc384","permalink":"https://deboranozza.com/publication/2023-ferret-explainers-transformers/","publishdate":"2023-05-02T14:48:20+01:00","relpermalink":"/publication/2023-ferret-explainers-transformers/","section":"publication","summary":"As Transformers are increasingly relied upon to solve complex NLP problems, there is an increased need for their decisions to be humanly interpretable. While several explainable AI (XAI) techniques for interpreting the outputs of transformer-based models have been proposed, there is still a lack of easy access to using and comparing them.We introduce ferret, a Python library to simplify the use and comparisons of XAI methods on transformer-based classifiers.With ferret, users can visualize and compare transformers-based models output explanations using state-of-the-art XAI methods on any free-text or existing XAI corpora. Moreover, users can also evaluate ad-hoc XAI metrics to select the most faithful and plausible explanations. To align with the recently consolidated process of sharing and using transformers-based models from Hugging Face, ferret interfaces directly with its Python library.In this paper, we showcase ferret to benchmark XAI methods used on transformers for sentiment analysis and hate speech detection. We show how specific methods provide consistently better explanations and are preferable in the context of transformer models.","tags":["BERT","NLP","interpretability"],"title":"ferret: a Framework for Benchmarking Explainers on Transformers","type":"publication"},{"authors":["Samia Touileb","Debora Nozza"],"categories":[],"content":"","date":1670544000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670544000,"objectID":"5d92f30200b04a92ce9594e899951021","permalink":"https://deboranozza.com/publication/2022-honest-harmful-scandinavian-language-model/","publishdate":"2022-12-09T14:48:20+01:00","relpermalink":"/publication/2022-honest-harmful-scandinavian-language-model/","section":"publication","summary":"Scandinavian countries are perceived as role-models when it comes to gender equality. With the advent of pre-trained language models and their widespread usage, we investigate to what extent gender-based harmful and toxic content exist in selected Scandinavian language models. We examine nine models, covering Danish, Swedish, and Norwegian, by manually creating template-based sentences and probing the models for completion. We evaluate the completions using two methods for measuring harmful and toxic completions and provide a thorough analysis of the results. We show that Scandinavian pre-trained language models contain harmful and gender-based stereotypes with similar values across all languages. This finding goes against the general expectations related to gender equality in Scandinavian countries and shows the possible problematic outcomes of using such models in real-world settings.","tags":["Hate Speech","BERT","NLP","dataset","multilingual"],"title":"Measuring Harmful Representations in Scandinavian Language Models","type":"publication"},{"authors":["Federico Bianchi","Pratyusha Kalluri","Esin Durmus","Faisal Ladhak","Myra Cheng","Debora Nozza","Tatsunori Hashimoto","Dan Jurafsky","James Zou","Aylin Caliskan"],"categories":[],"content":"","date":1667779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667779200,"objectID":"ce14a8624a17194aac51b73c1c12a44f","permalink":"https://deboranozza.com/publication/2022-text-to-image-stereotypes/","publishdate":"2022-11-07T14:48:20+01:00","relpermalink":"/publication/2022-text-to-image-stereotypes/","section":"publication","summary":"Machine learning models are now able to convert user-written text descriptions into naturalistic images. These models are available to anyone online and are being used to generate millions of images a day. We investigate these models and find that they amplify dangerous and complex stereotypes. Moreover, we find that the amplified stereotypes are difficult to predict and not easily mitigated by users or model owners. The extent to which these image-generation models perpetuate and amplify stereotypes and their mass deployment is cause for serious concern.","tags":["Vision","NLP","Bias"],"title":"Easily Accessible Text-to-Image Generation Amplifies Demographic Stereotypes at Large Scale","type":"publication"},{"authors":["Paul Röttger","Debora Nozza","Federico Bianchi","Dirk Hovy"],"categories":[],"content":"","date":1666224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666224000,"objectID":"a2ca0d19f38470541be45569c6948729","permalink":"https://deboranozza.com/publication/2022-strategies-hate-speech-detection-under-resourced-languages/","publishdate":"2022-10-20T14:48:20+01:00","relpermalink":"/publication/2022-strategies-hate-speech-detection-under-resourced-languages/","section":"publication","summary":"Hate speech is a global phenomenon, but most hate speech datasets so far focus on English-language content. This hinders the development of more effective hate speech detection models in hundreds of languages spoken by billions across the world. More data is needed, but annotating hateful content is expensive, time-consuming and potentially harmful to annotators. To mitigate these issues, we explore data-efficient strategies for expanding hate speech detection into under-resourced languages. In a series of experiments with mono- and multilingual models across five non-English languages, we find that 1) a small amount of target-language fine-tuning data is needed to achieve strong performance, 2) the benefits of using more such data decrease exponentially, and 3) initial fine-tuning on readily-available English data can partially substitute target-language data and improve model generalisability. Based on these findings, we formulate actionable recommendations for hate speech detection in low-resource language settings.","tags":["Hate Speech","NLP","multilingual"],"title":"Data-Efficient Strategies for Expanding Hate Speech Detection into Under-Resourced Languages","type":"publication"},{"authors":["Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1665705600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665705600,"objectID":"7d5f8cf4d905510b77ccbc6187ff4fa8","permalink":"https://deboranozza.com/publication/2022-prof-profanity-obfuscation-nlp/","publishdate":"2022-10-14T14:48:20+01:00","relpermalink":"/publication/2022-prof-profanity-obfuscation-nlp/","section":"publication","summary":"Work on hate speech has made the consideration of rude and harmful examples in scientific publications inevitable. This raises various problems, such as whether or not to obscure profanities. While science must accurately disclose what it does, the unwarranted spread of hate speech is harmful to readers, and increases its internet frequency. While maintaining publications' professional appearance, obfuscating profanities make it challenging to evaluate the content, especially for non-native speakers. Surveying 150 ACL papers, we discovered that obfuscation is usually employed for English but not other languages, and even so quite uneven. We discuss the problems with obfuscation and suggest a multilingual community resource called PrOf that has a Python module to standardize profanity obfuscation processes. We believe PrOf can help scientific publication policies to make hate speech work accessible and comparable, irrespective of language.","tags":["Hate Speech","NLP","multilingual"],"title":"The State of Profanity Obfuscation in Natural Language Processing Scientific Publications","type":"publication"},{"authors":["Giuseppe Attanasio","Debora Nozza","Federico Bianchi","Dirk Hovy"],"categories":[],"content":"","date":1665619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665619200,"objectID":"bcb8bb12e133a3d8b26d9091bc35a703","permalink":"https://deboranozza.com/publication/2022-limitation-diachronic-continuous-training/","publishdate":"2022-10-13T14:48:20+01:00","relpermalink":"/publication/2022-limitation-diachronic-continuous-training/","section":"publication","summary":"Language is constantly changing and evolving, leaving language models to quickly become outdated, both factually and linguistically. Recent research proposes we continuously update our models using new data. Continuous training allows us to teach language models about new events and facts and changing norms. However, continuous training also means continuous costs. We show there is currently limited evidence for the benefits of continuous training, be it for the actual downstream performance or the environmental cost. Our results show continuous training does not significantly improve performance. While it is clear that, sooner or later, our language models need to be updated, it is unclear when this effort is worth the cost. We call for a critical reflection about when and how to use continuous training and for more benchmarks to support this research direction.","tags":["NLP","BERT"],"title":"Is It Worth the (Environmental) Cost? Limited Evidence for the Benefits of Diachronic Continuous Training","type":"publication"},{"authors":[],"categories":null,"content":"An increasing propagation of hate speech has been detected on social media platforms (e.g., Twitter) where (pseudo-)anonymity enables people to target others without being recognized or easily traced. While this societal issue has attracted many studies in the NLP community, it comes with three important challenges. Hate speech detection models should be fair, work on every language, and consider the whole context (e.g., imagery). Solving these challenges will revolutionize the field of hate speech detection and help on creating a \u0026ldquo;universal\u0026rdquo; model. In this talk, I will present my contributions in this area along with my takes for future directions.\n","date":1664887172,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664887172,"objectID":"8b65c674c8c4049de574da8275d4a969","permalink":"https://deboranozza.com/talk/universal_hate_speech/","publishdate":"2022-10-04T14:39:32+02:00","relpermalink":"/talk/universal_hate_speech/","section":"talk","summary":"An increasing propagation of hate speech has been detected on social media platforms (e.g., Twitter) where (pseudo-)anonymity enables people to target others without being recognized or easily traced. While this societal issue has attracted many studies in the NLP community, it comes with three important challenges. Hate speech detection models should be fair, work on every language, and consider the whole context (e.g., imagery). Solving these challenges will revolutionize the field of hate speech detection and help on creating a universal model. In this talk, I will present my contributions in this area along with my takes for future directions.","tags":[],"title":"Roadmap to universal hate speech detection","type":"talk"},{"authors":["Giuseppe Attanasio","Eliana Pastor","Chiara Di Bonaventura","Debora Nozza"],"categories":[],"content":"","date":1659398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659398400,"objectID":"e0129daa5c73e7cb18e49d01714aa3c8","permalink":"https://deboranozza.com/publication/2022-ferret-explainers-transformers/","publishdate":"2022-08-02T14:48:20+01:00","relpermalink":"/publication/2022-ferret-explainers-transformers/","section":"publication","summary":"Many interpretability tools allow practitioners and researchers to explain Natural Language Processing systems. However, each tool requires different configurations and provides explanations in different forms, hindering the possibility of assessing and comparing them. A principled, unified evaluation benchmark will guide the users through the central question: which explanation method is more reliable for my use case? We introduce ferret, an easy-to-use, extensible Python library to explain Transformer-based models integrated with the Hugging Face Hub. It offers a unified benchmarking suite to test and compare a wide range of state-of-the-art explainers on any text or interpretability corpora. In addition, ferret provides convenient programming abstractions to foster the introduction of new explanation methods, datasets, or evaluation metrics.","tags":["BERT","NLP","interpretability"],"title":"ferret: a Framework for Benchmarking Explainers on Transformers","type":"publication"},{"authors":["Debora Nozza","Federico Bianchi","Giuseppe Attanasio"],"categories":[],"content":"","date":1657584000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657584000,"objectID":"e1aa310a2b39f2b3d80eb484d6acf1be","permalink":"https://deboranozza.com/publication/2022-hate-speech-detection-italian-social-media/","publishdate":"2022-07-12T14:48:20+01:00","relpermalink":"/publication/2022-hate-speech-detection-italian-social-media/","section":"publication","summary":"Online hate speech is a dangerous phenomenon that can (and should) be promptly counteracted properly. While Natural Language Processing supplies appropriate algorithms for trying to reach this objective, all research efforts are directed toward the English language. This strongly limits the classification power on non-English languages. In this paper, we test several learning frameworks for identifying hate speech in Italian text. We release HATE-ITA, a multi-language model trained on a large set of English data and available Italian datasets. HATE-ITA performs better than mono-lingual models and seems to adapt well also on language-specific slurs. We hope our findings will encourage the research in other mid-to-low resource communities and provide a valuable benchmarking tool for the Italian community.","tags":["Hate Speech","BERT","NLP"],"title":"HATE-ITA: Hate Speech Detection in Italian Social Media Text","type":"publication"},{"authors":["Paul Röttger","Haitham Seelawi","Debora Nozza","Zeerak Talat","Bertie Vidgen"],"categories":[],"content":"","date":1657584000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657584000,"objectID":"44e6c8311312a4c0b80faea18522c363","permalink":"https://deboranozza.com/publication/2022-multilingual-hatecheck-hate-speech-functional-tests/","publishdate":"2022-07-12T14:48:20+01:00","relpermalink":"/publication/2022-multilingual-hatecheck-hate-speech-functional-tests/","section":"publication","summary":"Hate speech detection models are typically evaluated on held-out test sets. However, this risks painting an incomplete and potentially misleading picture of model performance because of increasingly well-documented systematic gaps and biases in hate speech datasets. To enable more targeted diagnostic insights, recent research has thus introduced functional tests for hate speech detection models. However, these tests currently only exist for English-language content, which means that they cannot support the development of more effective models in other languages spoken by billions across the world. To help address this issue, we introduce Multilingual HateCheck (MHC), a suite of functional tests for multilingual hate speech detection models. MHC covers 34 functionalities across ten languages, which is more languages than any other hate speech dataset. To illustrate MHC’s utility, we train and test a high-performing multilingual hate speech detection model, and reveal critical model weaknesses for monolingual and cross-lingual applications.","tags":["Hate Speech","BERT","NLP"],"title":"Multilingual HateCheck: Functional Tests for Multilingual Hate Speech Detection Models","type":"publication"},{"authors":["Giuseppe Attanasio","Debora Nozza","Federico Bianchi"],"categories":[],"content":"","date":1651276800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651276800,"objectID":"8358f2dc7dc8713df3a0102aca07e999","permalink":"https://deboranozza.com/publication/2022-semeval-mami-perceiverio-misogyny-multimodal-meme/","publishdate":"2022-04-30T14:48:20+01:00","relpermalink":"/publication/2022-semeval-mami-perceiverio-misogyny-multimodal-meme/","section":"publication","summary":"In this paper, we describe the system proposed by the MilaNLP team for the Multimedia Automatic Misogyny Identification (MAMI) challenge. We use Perceiver IO as a multimodal late fusion over unimodal streams to address both sub-tasks A and B. We build unimodal embeddings using Vision Transformer (image) and RoBERTa (text transcript). We enrich the input representation using face and demographic recognition, image captioning, and detection of adult content and web entities. To the best of our knowledge, this work is the first to use Perceiver IO combining text and image modalities. The proposed approach outperforms unimodal and multimodal baselines.","tags":["Misogyny","Meme","Multimodal","PerceiverIO","Architectures"],"title":"MilaNLP at SemEval-2022 Task 5: Using Perceiver IO for Detecting Misogynous Memes with Text and Image Modalities","type":"publication"},{"authors":["Federico Bianchi","Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1649721600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649721600,"objectID":"c798f81abd0bcd706c51aa0ea04a2d12","permalink":"https://deboranozza.com/publication/2022-xlmemo-multilingual-emotion-prediction/","publishdate":"2022-04-12T14:48:20+01:00","relpermalink":"/publication/2022-xlmemo-multilingual-emotion-prediction/","section":"publication","summary":"Detecting emotion in text allows social and computational scientists to study how people behave and react to online events. However, developing these tools for different languages requires data that is not always available. This paper collects the available emotion detection datasets across 19 languages. We train a multilingual emotion prediction model for social media data, XLM-EMO. The model shows competitive performance in a zero-shot setting, suggesting it is helpful in the context of low-resource languages. We release our model to the community so that interested researchers can directly use it.","tags":["Sentiment Analysis","Emotion Detection","Italian","BERT","NLP","dataset","multilingual"],"title":"XLM-EMO: Multilingual Emotion Prediction in Social Media Text","type":"publication"},{"authors":null,"categories":null,"content":"\r[19/07/23] Come work with me! New position open for a postdoc starting this year. See the call here\n[13/07/23] Organizer of the 7th Workshop on Online Abuse and Harms (WOAH) at ACL 2023.\n[13/07/23] New paper on Respectful or Toxic? Using Zero-Shot Learning with Language Models to Detect Hate Speech published at WOAH workshop at ACL 2023.\n[13/07/23] New paper on What about \u0026lsquo;\u0026lsquo;em\u0026rsquo;'? How Commercial Machine Translation Fails to Handle (Neo-)Pronouns published at ACL 2023.\n[13/07/23] New paper on The State of Profanity Obfuscation in Natural Language Processing Scientific Publications published at Findings of ACL 2023.\n[13/07/23] New paper on A Multi-dimensional study on Bias in Vision-Language models published at Findings of ACL 2023.\n[05/07/23] Invited Talk about Fairness of Generative AI for the Italian Publishers Association (AIE).\n[18/06/23] My first editorial piece has been published on Sole 24 ore! You can read it here.\n[07/06/23] New paper on Easily Accessible Text-to-Image Generation Amplifies Demographic Stereotypes at Large Scale published at FAACT 2023.\n[05/06/23] Organizer of the ICWSM 2023 Data Challenge: Temporal social data at ICWSM 2023.\n[10/05/23] Webinar Talk for A+I Algoritmi+Inclusivi about the positive impact of AI.\n[09/05/23] Invited Talk at #ScienzaEspresso at #casaXiaomi in Milan about Fairness of Generative AI.\n[07/05/23] New paper on A Cross-Lingual Study of Homotransphobia on Twitter published at C3NLP workshop at EACL 2023.\n[07/05/23] New paper on ferret: a Framework for Benchmarking Explainers on Transformers published at EACL 2023: System Demonstration.\n[27/04/23] Workshop Speaker at the NCRM/Exeter Computational Communication Methods Spring School.\n[15/12/22] Invited Talk at GESIS Leibniz Institute for the Social Sciences.\n[30/11/22] Organizer of the 6th Workshop on Natural Language for Artificial Intelligence (NL4AI).\n[07/10/22] Invited Talk at INRIA Paris.\n[04/10/22] Invited Talk at Fondazione Bruno Kessler in Trento.\n[01/09/22] Officially started as Assistant Professor in Computing Sciences at Bocconi University.\n[19/07/22] Seminar presentation on the Roadmap to Universal Hate Speech Detection at the Digital Democracies Institute at Simon Fraser University.\n[18/07/22] Seminar presentation on the Roadmap to Universal Hate Speech Detection at the University of British Columbia.\n[12/07/22] My #betterposter at NAACL 2022.\n[12/07/22] New paper on HATE-ITA: Hate Speech Detection in Italian Social Media Text published at WOAH workshop at NAACL 2022.\n[12/07/22] New paper on Multilingual HateCheck: Functional Tests for Multilingual Hate Speech Detection Models published at WOAH workshop at NAACL 2022.\n[27/06/22] Invited speaker at Fairness in Artificial Intelligence workshop organized by Bocconi University in partnership with Associazione EDGE.\n[02/03/22] 5 paper on hate speech detection, bias, and multilinguality published at ACL workshops.\n[01/03/22] New paper on Entropy-based Attention Regularization Frees Unintended Bias Mitigation from Lists published at ACL findings.\n[06/08/21] My first single-authored paper on Exposing the limits of Zero-shot Cross-lingual Hate Speech Detection published at ACL.\n","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"a0812ae5f3c926fea6faf4472cefc8e2","permalink":"https://deboranozza.com/news/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/news/","section":"","summary":"List of news.\n","tags":[],"title":"News","type":"page"},{"authors":["Debora Nozza"],"categories":[],"content":"","date":1627862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627862400,"objectID":"21f8b8f0a896aaf439bea0d701f2ea7d","permalink":"https://deboranozza.com/publication/2021-zeroshot-crosslingual-hate-speech/","publishdate":"2021-05-06T14:48:20+01:00","relpermalink":"/publication/2021-zeroshot-crosslingual-hate-speech/","section":"publication","summary":"Reducing and counter-acting hate speech on Social Media is a significant concern. Most of the proposed automatic methods are conducted exclusively on English and very few consistently labeled, non-English resources have been proposed. Learning to detect hate speech on English and transferring to unseen languages seems an immediate solution. This work is the first to shed light on the limits of this zero-shot, cross-lingual transfer learning framework for hate speech detection. We use benchmark data sets in English, Italian, and Spanish to detect hate speech towards immigrants and women. Investigating post-hoc explanations of the model, we discover that non-hateful, language-specific taboo interjections are misinterpreted as signals of hate speech. Our findings demonstrate that zero-shot, cross-lingual models cannot be used as they are, but need to be carefully designed.","tags":["Hate Speech","BERT","NLP"],"title":"Exposing the limits of Zero-shot Cross-lingual Hate Speech Detection","type":"publication"},{"authors":["Debora Nozza","Federico Bianchi","Dirk Hovy"],"categories":[],"content":"","date":1622937600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622937600,"objectID":"3c6a04000acf7b38009176972f9bf596","permalink":"https://deboranozza.com/publication/2021-honest-hurtful-language-model/","publishdate":"2021-03-29T14:48:20+01:00","relpermalink":"/publication/2021-honest-hurtful-language-model/","section":"publication","summary":"Language models have revolutionized the field of NLP. However, language models capture and proliferate hurtful stereotypes, especially in text generation. Our results show that **4.3% of the time, language models complete a sentence with a hurtful word**. These cases are not random, but follow language and gender-specific patterns. We propose a score to measure hurtful sentence completions in language models (HONEST). It uses a systematic template- and lexicon-based bias evaluation methodology for six languages. Our findings suggest that these models replicate and amplify deep-seated societal stereotypes about gender roles. Sentence completions refer to sexual promiscuity when the target is female in 9% of the time, and in 4% to homosexuality when the target is male.  The results raise questions about the use of these models in production settings.","tags":["Hate Speech","BERT","NLP"],"title":"HONEST: Measuring Hurtful Sentence Completion in Language Models","type":"publication"},{"authors":["Debora Nozza","Pikakshi Manchanda","Elisabetta Fersini","Matteo Palmonari","Enza Messina"],"categories":[],"content":"","date":1622937600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622937600,"objectID":"6865d232228111571a373ed18a41937e","permalink":"https://deboranozza.com/publication/2021_learningtoadapt/","publishdate":"2021-03-29T14:48:20+01:00","relpermalink":"/publication/2021_learningtoadapt/","section":"publication","summary":"The task of Named Entity Recognition (NER) is aimed at identifying named entities in a given text and classifying them into pre-defined domain entity types such as persons, organizations, locations. Most of the existing NER systems make use of generic entity type classification schemas, however, the comparison and integration of (more or less) different entity types among different NER systems is a complex problem even for human experts. In this paper, we propose a supervised approach called L2AWE (Learning To Adapt with Word Embeddings) which aims at adapting a NER system trained on a source classification schema to a given target one. In particular, we validate the hypothesis that the embedding representation of named entities can improve the semantic meaning of the feature space used to perform the adaptation from a source to a target domain. The results obtained on benchmark datasets of informal text show that L2AWE not only outperforms several state of the art models, but it is also able to tackle errors and uncertainties given by NER systems.","tags":["Named Entity Recognition","Domain Adaptation","Social Media","NLP"],"title":"LearningToAdapt with word embeddings: Domain adaptation of Named Entity Recognition systems","type":"publication"},{"authors":["Federico Bianchi","Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1621123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621123200,"objectID":"ede87cdeecd57ecdb6e7b020668ace0c","permalink":"https://deboranozza.com/publication/2021-feelit-italian-sentiment-emotion/","publishdate":"2021-03-28T14:48:20+01:00","relpermalink":"/publication/2021-feelit-italian-sentiment-emotion/","section":"publication","summary":"Sentiment analysis is a common task to understand people's reactions online. Still, we often need more nuanced information: is the post negative because the user is angry or because they are sad? An abundance of approaches has been introduced for tackling both tasks. However, at least for Italian, they all treat only one of the tasks at a time. We introduce FEEL-IT, a novel benchmark corpus of Italian Twitter posts annotated with four basic emotions: **anger**, **fear**, **joy**, **sadness**. By collapsing them, we can also do sentiment analysis. We evaluate our corpus on benchmark datasets for both emotion and sentiment classification,  obtaining competitive results. We release an [open-source Python library](https://github.com/MilaNLProc/feel-it), so researchers can use a model trained on FEEL-IT for inferring both sentiments and emotions from Italian text.","tags":["Sentiment Analysis","Emotion Detection","Italian","BERT","NLP","dataset"],"title":"FEEL-IT: Emotion and Sentiment Classification for the Italian Language","type":"publication"},{"authors":["Tommaso Fornaciari","Federico Bianchi","Debora Nozza","Dirk Hovy"],"categories":[],"content":"","date":1621123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621123200,"objectID":"3bc06910533e6771816b1c186a6e9ade","permalink":"https://deboranozza.com/publication/2021-wassa-emotion-multitask/","publishdate":"2021-03-27T14:48:20+01:00","relpermalink":"/publication/2021-wassa-emotion-multitask/","section":"publication","summary":"The paper describes the MilaNLP team’s submission (Bocconi University, Milan) in the WASSA 2021 Shared Task on Empathy Detection and Emotion Classification. We focus on Track 2 - Emotion Classification - which consists of predicting the emotion of reactions to English news stories at the essay-level. We test different models based on multi-task and multi-input frameworks. The goal was to better exploit all the correlated information given in the data set. We find, though, that empathy as an auxiliary task in multi-task learning and demographic attributes as additional input provide worse performance with respect to single-task learning. While the result is competitive in terms of the competition, our results suggest that emotion and empathy are not related tasks - at least for the purpose of prediction.","tags":["Emotion Detection","BERT","NLP"],"title":"MilaNLP @ WASSA: Does BERT Feel Sad When You Cry?","type":"publication"},{"authors":["Federico Bianchi","Silvia Terragni","Dirk Hovy","Debora Nozza","Elisabetta Fersini"],"categories":null,"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"b4e481bdc36e151c5f7c537366aa81d6","permalink":"https://deboranozza.com/publication/2021-crosslingual-topic-model/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/publication/2021-crosslingual-topic-model/","section":"publication","summary":"We introduce a novel topic modeling method that can make use of contextulized embeddings (e.g., BERT) to do zero-shot cross-lingual topic modeling.","tags":["NLP","Topic Modeling","BERT","Language Models"],"title":"Cross-lingual Contextualized Topic Models with Zero-shot Learning","type":"publication"},{"authors":["Elisabetta Fersini","Debora Nozza","Paolo Rosso"],"categories":[],"content":"","date":1608163200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608163200,"objectID":"5baf0140a6c5a094edef6eaf88b98434","permalink":"https://deboranozza.com/publication/2020_automatic_misogyny_identification/","publishdate":"2021-02-15T14:48:20+01:00","relpermalink":"/publication/2020_automatic_misogyny_identification/","section":"publication","summary":"**Automatic Misogyny Identification (AMI)** is a **shared task** proposed at the Evalita 2020 evaluation campaign. The AMI challenge, based on **Italian tweets**, is organized into two subtasks: (1) Subtask A about misogyny and aggressiveness identification and (2) Subtask B about the **fairness** of the model. At the end of the evaluation phase, we received a total of 20 runs for Subtask A and 11 runs for Subtask B, submitted by 8 teams. In this paper, we present an overview of the AMI shared task, the datasets, the evaluation methodology, the results obtained by the participants and a discussion about the methodology adopted by the teams. Finally, we draw some conclusions and discuss future work.","tags":["Misogyny Detection","Bias","Hate Speech","International Challenge","Social Media","NLP"],"title":"AMI @ EVALITA2020: Automatic Misogyny Identification","type":"publication"},{"authors":["Silvia Terragni","Debora Nozza","Elisabetta Fersini","Enza Messina"],"categories":[],"content":"","date":1605744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605744000,"objectID":"fd4cfa79ddf59bc1c74b98309ae5b50e","permalink":"https://deboranozza.com/publication/2020_concept_document_topic_models/","publishdate":"2021-02-15T14:48:20+01:00","relpermalink":"/publication/2020_concept_document_topic_models/","section":"publication","summary":"Topic models have been widely used to discover hidden topics in a collection of documents. In this paper, we propose to investigate the role of two different types of relational information, i.e. document relationships and concept relationships. While exploiting the document network significantly improves topic coherence, the introduction of concepts and their relationships does not influence the results both quantitatively and qualitatively.","tags":["Topic Model","Representation learning","NLP","Relational"],"title":"Which Matters Most? Comparing the Impact of Concept and Document Relationships in Topic Models","type":"publication"},{"authors":[],"categories":null,"content":" ","date":1602506372,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602506372,"objectID":"791ab56916732033cf231c2b2696d673","permalink":"https://deboranozza.com/talk/etica_bias_ai/","publishdate":"2021-04-09T14:39:32+02:00","relpermalink":"/talk/etica_bias_ai/","section":"talk","summary":"","tags":[],"title":"Etica e bias nell'intelligenza artificiale","type":"talk"},{"authors":[],"categories":null,"content":"","date":1602506372,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602506372,"objectID":"f356c837512550ebb948d00c053ffb8c","permalink":"https://deboranozza.com/talk/potential_pitfalls_of_algorithms/","publishdate":"2021-04-09T14:39:32+02:00","relpermalink":"/talk/potential_pitfalls_of_algorithms/","section":"talk","summary":"","tags":[],"title":"The Potential Pitfalls of Algorithms","type":"talk"},{"authors":["Elisabetta Fersini","Debora Nozza","Giulia Boifava"],"categories":[],"content":"","date":1585785600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585785600,"objectID":"8cb988ef9d699daf2aae444d0c305b05","permalink":"https://deboranozza.com/publication/2020_profiling_italian_misogynist/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2020_profiling_italian_misogynist/","section":"publication","summary":"**Hate speech** may take different forms in online social environments.  In this paper, we address the problem of automatic detection of misogynous language on **Italian tweets** by focusing  both on  raw text and stylometric profiles. The proposed exploratory investigation about the adoption of stylometry for enhancing  the recognition capabilities of machine learning models has demonstrated that profiling users can lead to good discrimination of misogynous and not misogynous contents.","tags":["Hate Speech","Misogyny Detection","NLP"],"title":"Profiling Italian Misogynist: An Empirical Study","type":"publication"},{"authors":["Debora Nozza","Federico Bianchi","Dirk Hovy"],"categories":[],"content":"","date":1583020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583020800,"objectID":"9ded9b5d728733baae303b76b3f9c388","permalink":"https://deboranozza.com/publication/2020_bertlang/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2020_bertlang/","section":"publication","summary":"Recently, Natural Language Processing (NLP) has witnessed an impressive progress in many areas, due to the advent of novel, pretrained contextual representation models. In particular, Devlin et al. (2019) proposed a model, called BERT (Bidirectional Encoder Representations from Transformers), which enables researchers to obtain state-of-the art performance on numerous NLP tasks by fine-tuning the representations on their data set and task, without the need for developing and training highly-specific architectures. The authors also released multilingual BERT (mBERT), a model trained on a corpus of 104 languages, which can serve as a universal language model. This model obtained impressive results on a zero-shot cross-lingual natural inference task. Driven by the potential of BERT models, the NLP community has started to investigate and generate an abundant number of BERT models that are trained on a particular language, and tested on a specific data domain and task. This allows us to evaluate the true potential of mBERT as a universal language model, by comparing it to the performance of these more specific models. This paper presents the current state of the art in language-specific BERT models, providing an overall picture with respect to different dimensions (i.e. architectures, data domains, and tasks). Our aim is to provide an immediate and straightforward overview of the commonalities and differences between Language-Specific (language-specific) BERT models and mBERT. We also provide an interactive and constantly updated website that can be used to explore the information we have collected, at [https://bertlang.unibocconi.it](https://bertlang.unibocconi.it/).","tags":["multilingual","BERT","Representation learning","NLP"],"title":"What the [MASK]? Making Sense of Language-Specific BERT Models","type":"publication"},{"authors":["Debora Nozza","Elisabetta Fersini","Enza Messina"],"categories":[],"content":"","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580515200,"objectID":"3322cec4e3ba1f559b437710b3cae887","permalink":"https://deboranozza.com/publication/2019_cage/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2019_cage/","section":"publication","summary":"In this paper we deal with complex attributed graphs which can exhibit rich connectivity patterns and whose nodes are often associated with attributes, such as text or images. In order to analyze these graphs, the primary challenge is to find an effective way to represent them by preserving both structural properties and node attribute information. To create low-dimensional and meaningful embedded representations of these complex graphs, we propose a fully unsupervised model based on Deep Learning architectures, called Constrained Attributed Graph Embedding model (CAGE). The main contribution of the proposed model is the definition of a novel two-phase optimization problem that explicitly models node attributes to obtain a higher representation expressiveness while preserving the local and the global structural properties of the graph. We validated our approach on two different benchmark datasets for node classification. Experimental results demonstrate that this novel representation provides significant improvements compared to state of the art approaches, also showing higher robustness with respect to the size of the training data.","tags":["Deep learning","Representation learning","Graph embedding","Attributed graph","NLP"],"title":"CAGE: Constrained deep Attributed Graph Embedding","type":"publication"},{"authors":null,"categories":["hate speech"],"content":"While the exponential growth of Social Media such as Twitter and Facebook has permit people to freely express themselves in various forms (text, video, images), these new sources of communication, where anonymity or pseudo-anonymity enables the possibility to afflict a target without being recognized or traced, has led to an increasing propagation of hate speech. Automatic Machine Learning models for the detection of Hate Speech could help in preventing or automatically reporting these misbehaviors and consequently reduce the episodes of misogyny, racism, homophobia and cyberbullying. This could be helpful both for protecting individuals’ health and also to monitor public reactions to events.\nIn order to provide a benchmark dataset for Hate Speech and Misogyny Detection, I have contributed to the organization of the Automatic Misogyny Identification(AMI) shared task at Evalita 2018 and 2020 in Italian and English language and of the HatEval task at SemEval 2019 about the detection of hate speech against immigrants and women in Spanish and English messages extracted from Twitter.\nThese tasks permit to create and share the first labelled corpora for misogyny detection in Spanish and Italian. I firmly believe that we still have a long way to go: there are 3,909 written languages in the world, most without misogyny data sets. Moreover, we need to assure that data collection methodologies are the same across all languages in order for them to be valuable. 🌎🌍🌏\nIn my paper at ACL 2021, I demonstrated that zero-shot, cross-lingual transfer learning framework, in its traditional settings, is not a feasible solution for solving the lack of models and labeled corpora for hate speech detection. Limits are related to the high presence of language- and target-specific taboo interjections in non-hateful contexts, like porca puttana in Italian or puta in Spanish. I argue that hate speech is language specific, and NLP approaches to identifying hate speech must account for that specificity. 🔍\nFurther limitations of creating hate speech detection models can be found on popularly employed pretrained language models. Indeed, in my paper presented at NAACL 2021, I show that 4.3% of the time language models complete a sentence with a hurtful word (sentence completions refer to sexual promiscuity when the target is female in 9% of the time, and in 4% to homosexuality when the target is male)⚠️. When the subjects belong to the LGBTQIA+ community, the problem is even higher: the most likely LLM-generated completion is an identity attack 13% of the time (published at LT-EDI workshop at ACL 2022). For sistematicaly measure this issue, we propose HONEST a score to measure hurtful sentence completions in any language models.\nIn my work presented at International Conference on Web Intelligence (WI \u0026lsquo;19), I made some additional investigation on the presence of unintended bias in machine learning models for Misogyny Detection. This can lead the models to recognize positive or neutral texts as hate speech texts only because it contains certain terms (e.g. woman, girl), not guaranteeing fairness. Can you imagine seeing \u0026ldquo;You\u0026rsquo;re a smart woman\u0026rdquo; predicted as misogynous just because it\u0026rsquo;s talking about women? 🤦‍♀️ Exploring post-hoc interpretability models for misogyny detection, further demonstrated this problem. Models (like BERT) are paying too much attention to words that do not carry misogynous meaning (e.g. woman) (published at NLP-Power workshop at ACL 2022).\nIn my recent paper at ACL 2022 findings, we introduce a novel technique to exactly counteract this issue of unintended bias. We propose Entropy-based Attention Regularization (EAR 👂) to discourage overfitting to training-specific terms of Transformer-based models (e.g., BERT). The resulting model matches or exceeds state-of-the-art performance for hate speech classification and bias metrics on three benchmark corpora in English and Italian\n🎙️🎙️ Check out my latest interview on Ethics and bias in Artificial Intelligence!!\n","date":1580083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580083200,"objectID":"28d5fb5b3f99e9073df28f372fa65e6d","permalink":"https://deboranozza.com/project/hate_speech_misogyny_detection/","publishdate":"2020-01-27T00:00:00Z","relpermalink":"/project/hate_speech_misogyny_detection/","section":"project","summary":"How fair Machine Learning models could solve Hate Speech and Misogyny Detection?","tags":["hate speech","misogyny detection","nlp"],"title":"Hate Speech and Misogyny Detection","type":"project"},{"authors":["Debora Nozza","Claudia Volpetti","Elisabetta Fersini"],"categories":[],"content":"","date":1571011200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571011200,"objectID":"78e17267f4b5efee4bc7e8a3b29a4297","permalink":"https://deboranozza.com/publication/2019_unintended_bias_misogyny_detection/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2019_unintended_bias_misogyny_detection/","section":"publication","summary":"During the last years, the phenomenon of **hate against women** increased exponentially especially in online environments such as microblogs. Although this alarming phenomenon has triggered many studies both from computational linguistic and machine learning points of view, less effort has been spent to analyze if those misogyny detection models are affected by an **unintended bias**. This can lead the models to associate unreasonably high misogynous scores to a non-misogynous text only because it contains certain terms, called identity, terms. This work is the first attempt to address the problem of measuring and mitigating unintended bias in machine learning models trained for the misogyny detection task. We propose a *novel synthetic test set* that can be used as evaluation framework for measuring the unintended bias and different mitigation strategies specific for this task. Moreover, we provide a *misogyny detection model* that demonstrate to obtain the best classification performance in the state-of-the-art. Experimental results on recently introduced bias metrics confirm the ability of the bias mitigation treatment to reduce the unintended bias of the proposed misogyny detection model.","tags":["Deep learning","Hate Speech","Bias","Misogyny Detection","NLP"],"title":"Unintended Bias in Misogyny Detection","type":"publication"},{"authors":["Debora Nozza","Cezar Sas","Elisabetta Fersini","Enza Messina"],"categories":[],"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"88e56da2e740152719c11eb7660274c0","permalink":"https://deboranozza.com/publication/2019_word_embeddings_named_entity_linking/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2019_word_embeddings_named_entity_linking/","section":"publication","summary":"The huge amount of textual user-generated content on the Web has incredibly grown in the last decade, creating new relevant opportunities for different real-world applications and domains. In particular, microblogging platforms enables the collection of continuously and instantly updated information. The organization and extraction of valuable knowledge from these contents are fundamental for ensuring profitability and efficiency to companies and institutions. This paper presents an unsupervised model for the task of Named Entity Linking in microblogging environments. The aim is to link the named entity mentions in a text with their corresponding knowledge-base entries exploiting a novel heterogeneous representation space characterized by more meaningful similarity measures between words and named entities, obtained by Word Embeddings. The proposed model has been evaluated on different benchmark datasets proposed for Named Entity Linking challenges for English and Italian language. It obtains very promising performance given the highly challenging environment of user-generated content over microblogging platforms.","tags":["Representation learning","Named Entity Linking","NLP","Social Media"],"title":"Word Embeddings for Unsupervised Named Entity Linking","type":"publication"},{"authors":["Valerio Basile","Cristina Bosco","Elisabetta Fersini","Debora Nozza","Viviana Patti","Francisco Rangel","Paolo Rosso","Manuela Sanguinetti"],"categories":[],"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"4afc1dc6099885e3e608720ca17d3fb1","permalink":"https://deboranozza.com/publication/2019_semeval_hateval/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2019_semeval_hateval/","section":"publication","summary":"The paper describes the organization of the SemEval 2019 Task 5 about the detection of **hate speech against immigrants and women** in **Spanish and English** messages extracted from Twitter. The task is organized in two related classification subtasks: a main binary subtask for detecting the presence of hate speech, and a finer-grained one devoted to identifying further features in hateful contents such as the aggressive attitude and the target harassed, to distinguish if the incitement is against an individual rather than a group. HatEval has been one of the most popular tasks in SemEval-2019 with a total of 108 submitted runs for Subtask A and 70 runs for Subtask B, from a total of 74 different teams. Data provided for the task are described by showing how they have been collected and annotated. Moreover, the paper provides an analysis and discussion about the participant systems and the results they achieved in both subtasks.","tags":["Hate Speech","Misogyny Detection","International Challenge","Social Media","NLP"],"title":"SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter","type":"publication"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://deboranozza.com/contact/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"A little more about me and how to get in touch","tags":null,"title":"About / Contact","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"https://deboranozza.com/projects/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"See some of the projects I have worked on","tags":null,"title":"Projects","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"65de3680a280f6bf29dc34fe1adad5a6","permalink":"https://deboranozza.com/talks/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/talks/","section":"","summary":"Upcoming and recent talks","tags":null,"title":"Talks","type":"widget_page"},{"authors":["Elisabetta Fersini","Debora Nozza","Paolo Rosso"],"categories":[],"content":"","date":1543622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543622400,"objectID":"d5a83f859046eaea0ffb66f9e0003e31","permalink":"https://deboranozza.com/publication/2018_automatic_misogyny_identification/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2018_automatic_misogyny_identification/","section":"publication","summary":"**Automatic Misogyny Identification** (AMI) is a new **shared task** proposed for the first time at the Evalita 2018 evaluation campaign. The AMI challenge, based on both **Italian and English** tweets, is distinguished into two subtasks, i.e. Subtask A on misogyny identification and Subtask B about misogynistic behaviour categorization and target classification. Regarding the Italian language, we have received a total of 13 runs for Subtask A and 11 runs for Subtask B. Concerning the English language, we received 26 submissions for Subtask A and 23 runs for Subtask B. The participating systems have been distinguished according to the language, counting 6 teams for Italian and 10 teams for English. We present here an overview of the AMI shared task, the datasets, the evaluation methodology, the results obtained by the participants and a discussion of the methodology adopted by the teams. Finally, we draw some conclusions and discuss future work","tags":["Misogyny Detection","Hate Speech","International Challenge","Social Media","NLP"],"title":"Overview of the Evalita 2018 Task on Automatic Misogyny Identification (AMI)","type":"publication"},{"authors":["Valerio Basile","Elena Cabrio","Fabien Gandon","Debora Nozza"],"categories":[],"content":"","date":1541030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541030400,"objectID":"972e3c13fde8ad2a42623360bb597a75","permalink":"https://deboranozza.com/publication/2018_mapping_labels_web_resources/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2018_mapping_labels_web_resources/","section":"publication","summary":"Mapping natural language terms to a Web knowledge base enriches information systems without additional context, with new relations and properties from the Linked Open Data. In this paper we formally define such task, which is related to word sense disambiguation, named entity recognition and ontology matching. We provide a manually annotated dataset of labels linked to DBpedia as a gold standard for evaluation, and we use it to experiment with a number of methods, including a novel algorithm that leverages the specific characteristics of the mapping task. The empirical evidence confirms that general term mapping is a hard task, that cannot be easily solved by applying existing methods designed for related problems. However, incorporating NLP ideas such as representing the context and a proper treatment of multiword expressions can significantly boost the performance, in particular the coverage of the mapping. Our findings open up the challenge to find new ways of approaching term mapping to Web resources and bridging the gap between natural language and the Semantic Web.","tags":["Word Sense Disambiguation","Semantic Web","NLP"],"title":"Mapping Natural Language Labels to Structured Web Resources","type":"publication"},{"authors":["Federico Bianchi","Matteo Palmonari","Debora Nozza"],"categories":[],"content":"","date":1535760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535760000,"objectID":"17409a6f27c0a4c74f9eb8df7168dedf","permalink":"https://deboranozza.com/publication/2018_encoding_time_entity_embeddings/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2018_encoding_time_entity_embeddings/","section":"publication","summary":"Knowledge Graphs (KG) are widely used abstractions to represent entity-centric knowledge. Approaches to embed entities, entity types and relations represented in the graph into vector spaces - often referred to as KG embeddings - have become increasingly popular for their ability to capture the similarity between entities and support other reasoning tasks. However, representation of time has received little attention in these approaches. In this work, we make a first step to encode time into vector-based entity representations using a text-based KG embedding model named Typed Entity Embeddings (TEEs). In TEEs, each entity is represented by a vector that represents the entity and its type, which is learned from entity mentions found in a text corpus. Inspired by evidence from cognitive sciences and application-oriented concerns, we propose an approach to encode representations of years into TEEs by aggregating the representations of the entities that occur in event-based descriptions of the years. These representations are used to define two time-aware similarity measures to control the implicit effect of time on entity similarity. Experimental results show that the linear order of years obtained using our model is highly correlated with natural time flow and the effectiveness of the time-aware similarity measure proposed to flatten the time effect on entity similarity.","tags":["Representation learning","Time","NLP"],"title":"Towards encoding time in text-based entity embeddings","type":"publication"},{"authors":["Flavio Massimiliano Cecchini","Elisabetta Fersini","Pikakshi Manchanda","Enza Messina","Debora Nozza","Matteo Palmonari","Cezar Sas"],"categories":[],"content":"","date":1535760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535760000,"objectID":"15e7c778135f96330f6c16e14f967f5b","permalink":"https://deboranozza.com/publication/2016_named_entity_linking_italian_tweets/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2016_named_entity_linking_italian_tweets/","section":"publication","summary":"This paper describes the framework proposed by the UNIMIB Team for the task of Named Entity Recognition and Linking of Italian tweets (NEEL-IT). The proposed pipeline, which represents an entry level system, is composed of three main steps: (1) Named Entity Recognition using Conditional Random Fields, (2) Named Entity Linking by considering both Supervised and Neural-Network Language models, and (3) NIL clustering by using a graph-based approach.","tags":["Named Entity Linking","Social Media","NLP"],"title":"UNIMIB@ NEEL-IT: Named Entity Recognition and Linking of Italian Tweets","type":"publication"},{"authors":null,"categories":null,"content":"My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","date":1530140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530140400,"objectID":"53e892b8b41cc4caece1cfd5ef21d6e7","permalink":"https://deboranozza.com/license/","publishdate":"2018-06-28T00:00:00+01:00","relpermalink":"/license/","section":"","summary":"My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","tags":null,"title":"LICENSE: CC-BY-SA","type":"page"},{"authors":["Elisabetta Fersini","Pikakshi Manchanda","Enza Messina","Debora Nozza","Matteo Palmonari"],"categories":[],"content":"","date":1525132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525132800,"objectID":"ceb1060eaa8ef517c81f0b0aed102c74","permalink":"https://deboranozza.com/publication/2018_adapting_named_entity_types/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2018_adapting_named_entity_types/","section":"publication","summary":"Given the potential rise in the amount of user-generated content on social network, research efforts towards Information Extraction have significantly increased, giving leeway to the emergence of numerous *Named Entity Recognition* (NER) systems. Based on varying application scenarios and/or requirements, different NER systems use different entity classification schemas/ontologies to classify the discovered entity mentions into entity types. Indeed, comparisons and integrations among NER systems become complex. The situation is further worsened due to varying granularity levels of such ontologies used to train the NER systems. This problem has been approached in the state of the art by developing a deterministic manual mapping between concepts belonging to different ontologies. In this paper, we discuss the limitations of these methods and, inspired by a transfer learning paradigm, we propose a novel approach named LearningToAdapt (L2A) to mitigate them. L2A learns to transfer an input probability distribution over a set of ontology types defined in a source domain, into a probability distribution over the types of a new ontology in a target domain. By using the inferred probability distribution, we are able to re-classify the entity mentions using the most probable type in the target domain. Experiments conducted with benchmark data show remarkable performance, suggesting L2A as a promising approach for domain adaptation of NER systems.","tags":["Named Entity Recognition","Domain Adaptation","Social Media","NLP"],"title":"Adapting Named Entity Types to New Ontologies in a Microblogging Environment","type":"publication"},{"authors":["Debora Nozza","Elisabetta Fersini","Enza Messina"],"categories":[],"content":"","date":1491004800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491004800,"objectID":"915d1a685e6d503a1ab591b67df2ed1a","permalink":"https://deboranozza.com/publication/2017_multiview_sentiment_corpus/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2017_multiview_sentiment_corpus/","section":"publication","summary":"Sentiment Analysis is a broad task that involves the analysis of various aspect of the natural language text. However, most of the approaches in the state of the art usually investigate independently each aspect, i.e. Subjectivity Classification, Sentiment Polarity Classification, Emotion Recognition, Irony Detection. In this paper we present a Multi-View Sentiment Corpus (MVSC), which comprises 3000 English microblog posts related the movie domain. Three independent annotators manually labelled MVSC, following a broad annotation schema about different aspects that can be grasped from natural language text coming from social networks. The contribution is therefore a corpus that comprises five different views for each message, i.e. subjective/objective, sentiment polarity, implicit/explicit, irony, emotion. In order to allow a more detailed investigation on the human labelling behaviour, we provide the annotations of each human annotator involved.","tags":["Sentiment Analysis","Social Media","NLP"],"title":"A Multi-View Sentiment Corpus","type":"publication"},{"authors":["Pikakshi Manchanda","Elisabetta Fersini","Matteo Palmonari","Debora Nozza","Enza Messina"],"categories":[],"content":"","date":1491004800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491004800,"objectID":"cd028a0cea8daf389db5f12eab9ff430","permalink":"https://deboranozza.com/publication/2017_adaptation_entity_types/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2017_adaptation_entity_types/","section":"publication","summary":"Numerous state-of-the-art **Named Entity Recognition** (NER) systems use different classification schemas/ontologies. Comparisons and integration among NER systems, thus, becomes complex. In this paper, we propose a transfer-learning approach where we use supervised learning methods to automatically learn mappings between ontologies of NER systems, where an input probability distribution over a set of entity types defined in a source ontology is mapped to a target distribution over the entity types defined for a target ontology. Experiments conducted with benchmark data show valuable re-classification performance of entity mentions, suggesting our approach as a promising one for domain adaptation of NER systems.","tags":["Named Entity Recognition","Domain Adaptation","Social Media","NLP"],"title":"Towards adaptation of named entity classification","type":"publication"},{"authors":["Debora Nozza","Fausto Ristagno","Matteo Palmonari","Elisabetta Fersini","Pikakshi Manchanda","Enza Messina"],"categories":[],"content":"","date":1491004800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491004800,"objectID":"e385c6625d3dfb101e1956287dfcf7a1","permalink":"https://deboranozza.com/publication/2017_twine/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2017_twine/","section":"publication","summary":"In the recent years, the amount of user generated contents shared on the Web has significantly increased, especially in social media environment, e.g. Twitter, Facebook, Google+. This large quantity of data has generated the need of reactive and sophisticated systems for capturing and understanding the underlying information enclosed in them. In this paper we present TWINE, a real-time system for the big data analysis and exploration of information extracted from Twitter streams. The proposed system based on a Named Entity Recognition and Linking pipeline and a multi-dimensional spatial geo-localization is managed by a scalable and flexible architecture for an interactive visualization of micropost streams insights.","tags":["Information Extraction","Named Entity Linking","Social Media","NLP"],"title":"TWINE: A real-time system for TWeet analysis via INformation Extraction","type":"publication"},{"authors":["Debora Nozza","Elisabetta Fersini","Enza Messina"],"categories":[],"content":"","date":1477958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477958400,"objectID":"b0a2dcdf0c3c49c269b52f0b6e3ba79c","permalink":"https://deboranozza.com/publication/2016_deep_learning_sentiment_domain_adaptation/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2016_deep_learning_sentiment_domain_adaptation/","section":"publication","summary":"Real world applications of machine learning in natural language processing can span many different domains and usually require a huge effort for the annotation of domain specific training data. For this reason, domain adaptation techniques have gained a lot of attention in the last years. In order to derive an effective domain adaptation, a good feature representation across domains is crucial as well as the generalisation ability of the predictive model. In this paper we address the problem of domain adaptation for sentiment classification by combining deep learning, for acquiring a cross-domain high-level feature representation, and ensemble methods, for reducing the cross-domain generalization error. The proposed adaptation framework has been evaluated on a benchmark dataset composed of reviews of four different Amazon category of products, significantly outperforming the state of the art methods.","tags":["Sentiment Analysis","Deep Learning","Domain Adaptation","Social Media","NLP"],"title":"Deep learning and ensemble methods for Domain Adaptation","type":"publication"},{"authors":["Debora Nozza","Elisabetta Fersini","Enza Messina"],"categories":[],"content":"","date":1477958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477958400,"objectID":"1e5ade32c5051334256ee44989f19abf","permalink":"https://deboranozza.com/publication/2016_unsupervised_irony_detection/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2016_unsupervised_irony_detection/","section":"publication","summary":"The automatic detection of figurative language, such as irony and sarcasm, is one of the most challenging tasks of Natural Language Processing (NLP). This is because machine learning methods can be easily misled by the presence of words that have a strong polarity but are used ironically, which means that the opposite polarity was intended. In this paper, we propose an unsupervised framework for domain-independent irony detection. In particular, to derive an unsupervised Topic-Irony Model (TIM), we built upon an existing probabilistic topic model initially introduced for sentiment analysis purposes. Moreover, in order to improve its generalization abilities, we took advantage of Word Embeddings to obtain domain-aware ironic orientation of words. This is the first work that addresses this task in unsupervised settings and the first study on the topic-irony distribution. Experimental results have shown that TIM is comparable, and sometimes even better with respect to supervised state of the art approaches for irony detection. Moreover, when integrating the probabilistic model with word embeddings (TIM+WE), promising results have been obtained in a more complex and real world scenario.","tags":["Irony Detection","Unsupervised Learning","Topic Model","Representation Learning","Social Media","NLP"],"title":"Unsupervised Irony Detection: A Probabilistic Model with Word Embeddings","type":"publication"},{"authors":["Debora Nozza","Daniele Maccagnola","Vincent Guigue","Enza Messina","Patrick Gallinari"],"categories":[],"content":"","date":1422748800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1422748800,"objectID":"c96f94822164cc2a5d7fdd55feb03f0a","permalink":"https://deboranozza.com/publication/2014_latent_representation_sentiment_analysis_social_network/","publishdate":"2020-02-29T14:48:20+01:00","relpermalink":"/publication/2014_latent_representation_sentiment_analysis_social_network/","section":"publication","summary":"The growing availability of social media platforms, in particular microblogs such as Twitter, opened new way to people for expressing their opinions. Sentiment Analysis aims at inferring the polarity of these opinions, but most of the existing approaches are based only on text, disregarding information that comes from the relationships among users and posts. In this paper we consider microblogs as heterogeneous networks and we use an approach based on latent representation of nodes to infer, given a specific topic, the sentiment polarity of posts and users at the same time. The experimental investigation show that our approach, by taking into account both content and relationship information, outperforms supervised classifiers based only on textual content.","tags":["Representation learning","Sentiment Analysis","NLP","Social Media","Relational"],"title":"A latent representation model for sentiment analysis in heterogeneous social networks","type":"publication"}]