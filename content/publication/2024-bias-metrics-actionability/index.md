---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: 'Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation
  Metrics in NLP'
authors: ["Pieter Delobelle","Giuseppe Attanasio","Debora Nozza","Su Lin Blodgett","Zeerak Talat"]
date: 2024-11-01
doi: ''
publishDate: '2025-03-10T18:19:02+01:00'
publication_types:
- '1'
publication: Proceedings of the 2024 Conference on Empirical Methods in Natural Language
  Processing
publication_short: Proceedings of the 2024 Conference on Empirical Methods in Natural
  Language Processing
abstract: "This paper introduces the concept of actionability in the context of bias\
  \ measures in natural language processing (NLP). We define actionability as the\
  \ degree to which a measure\u2019s results enable informed action and propose a\
  \ set of desiderata for assessing it. Building on existing frameworks such as measurement\
  \ modeling, we argue that actionability is a crucial aspect of bias measures that\
  \ has been largely overlooked in the literature.We conduct a comprehensive review\
  \ of 146 papers proposing bias measures in NLP, examining whether and how they provide\
  \ the information required for actionable results. Our findings reveal that many\
  \ key elements of actionability, including a measure\u2019s intended use and reliability\
  \ assessment, are often unclear or entirely absent.This study highlights a significant\
  \ gap in the current approach to developing and reporting bias measures in NLP.\
  \ We argue that this lack of clarity may impede the effective implementation and\
  \ utilization of these measures. To address this issue, we offer recommendations\
  \ for more comprehensive and actionable metric development and reporting practices\
  \ in NLP bias research."
summary: ''
tags:
- bias
- ethics
categories: []
featured: false
url_pdf: https://aclanthology.org/2024.emnlp-main.1207.pdf
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''
socialmedia_post: 'Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP" (Pieter Delobelle, Giuseppe Attanasio, {@debora}, Su Lin Blodgett, Zeerak Talat, 2024) highlights the need for clearer, actionable bias measures in NLP.'
image:
  caption: ''
  focal_point: Center
  preview_only: false
projects:
- personae
slides: ''
# 
---
