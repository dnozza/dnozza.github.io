<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>nlp on Debora Nozza</title><link>https://deboranozza.com/tags/nlp/</link><description>Recent content in nlp on Debora Nozza</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>&amp;copy; Debora Nozza, {year}</copyright><lastBuildDate>Wed, 12 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://deboranozza.com/tags/nlp/index.xml" rel="self" type="application/rss+xml"/><item><title>A Multi-dimensional study on Bias in Vision-Language models</title><link>https://deboranozza.com/publication/2023-multidimensional-bias-vision-language-models/</link><pubDate>Wed, 12 Jul 2023 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2023-multidimensional-bias-vision-language-models/</guid><description/></item><item><title>MilaNLP at SemEval-2023 Task 10: Ensembling Domain-Adapted and Regularized Pretrained Language Models for Robust Sexism Detection</title><link>https://deboranozza.com/publication/2023-milanlp-semeval-2023-task-10-ensembling-domain-adapted-regularized-pretrained-language-models-robust-sexism-detection/</link><pubDate>Wed, 12 Jul 2023 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2023-milanlp-semeval-2023-task-10-ensembling-domain-adapted-regularized-pretrained-language-models-robust-sexism-detection/</guid><description/></item><item><title>Respectful or Toxic? Using Zero-Shot Learning with Language Models to Detect Hate Speech</title><link>https://deboranozza.com/publication/2023-zero-shot-prompting-hate-speech/</link><pubDate>Wed, 12 Jul 2023 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2023-zero-shot-prompting-hate-speech/</guid><description/></item><item><title>The State of Profanity Obfuscation in Natural Language Processing Scientific Publications</title><link>https://deboranozza.com/publication/2023-prof-profanity-obfuscation-nlp/</link><pubDate>Wed, 12 Jul 2023 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2023-prof-profanity-obfuscation-nlp/</guid><description/></item><item><title>What about ''em''? How Commercial Machine Translation Fails to Handle (Neo-)Pronouns</title><link>https://deboranozza.com/publication/2023-commercial-machine-translation-fail-neopronouns/</link><pubDate>Wed, 12 Jul 2023 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2023-commercial-machine-translation-fail-neopronouns/</guid><description/></item><item><title>A Cross-Lingual Study of Homotransphobia on Twitter</title><link>https://deboranozza.com/publication/2023-cross-lingual-study-homotransphobia/</link><pubDate>Fri, 12 May 2023 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2023-cross-lingual-study-homotransphobia/</guid><description/></item><item><title>Easily Accessible Text-to-Image Generation Amplifies Demographic Stereotypes at Large Scale</title><link>https://deboranozza.com/publication/2023-text-to-image-stereotypes/</link><pubDate>Sun, 07 May 2023 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2023-text-to-image-stereotypes/</guid><description/></item><item><title>ferret: a Framework for Benchmarking Explainers on Transformers</title><link>https://deboranozza.com/publication/2023-ferret-explainers-transformers/</link><pubDate>Tue, 02 May 2023 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2023-ferret-explainers-transformers/</guid><description/></item><item><title>Measuring Harmful Representations in Scandinavian Language Models</title><link>https://deboranozza.com/publication/2022-honest-harmful-scandinavian-language-model/</link><pubDate>Fri, 09 Dec 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-honest-harmful-scandinavian-language-model/</guid><description/></item><item><title>Easily Accessible Text-to-Image Generation Amplifies Demographic Stereotypes at Large Scale</title><link>https://deboranozza.com/publication/2022-text-to-image-stereotypes/</link><pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-text-to-image-stereotypes/</guid><description/></item><item><title>Data-Efficient Strategies for Expanding Hate Speech Detection into Under-Resourced Languages</title><link>https://deboranozza.com/publication/2022-strategies-hate-speech-detection-under-resourced-languages/</link><pubDate>Thu, 20 Oct 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-strategies-hate-speech-detection-under-resourced-languages/</guid><description/></item><item><title>The State of Profanity Obfuscation in Natural Language Processing Scientific Publications</title><link>https://deboranozza.com/publication/2022-prof-profanity-obfuscation-nlp/</link><pubDate>Fri, 14 Oct 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-prof-profanity-obfuscation-nlp/</guid><description/></item><item><title>Is It Worth the (Environmental) Cost? Limited Evidence for the Benefits of Diachronic Continuous Training</title><link>https://deboranozza.com/publication/2022-limitation-diachronic-continuous-training/</link><pubDate>Thu, 13 Oct 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-limitation-diachronic-continuous-training/</guid><description/></item><item><title>ferret: a Framework for Benchmarking Explainers on Transformers</title><link>https://deboranozza.com/publication/2022-ferret-explainers-transformers/</link><pubDate>Tue, 02 Aug 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-ferret-explainers-transformers/</guid><description/></item><item><title>HATE-ITA: Hate Speech Detection in Italian Social Media Text</title><link>https://deboranozza.com/publication/2022-hate-speech-detection-italian-social-media/</link><pubDate>Tue, 12 Jul 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-hate-speech-detection-italian-social-media/</guid><description/></item><item><title>Multilingual HateCheck: Functional Tests for Multilingual Hate Speech Detection Models</title><link>https://deboranozza.com/publication/2022-multilingual-hatecheck-hate-speech-functional-tests/</link><pubDate>Tue, 12 Jul 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-multilingual-hatecheck-hate-speech-functional-tests/</guid><description/></item><item><title>XLM-EMO: Multilingual Emotion Prediction in Social Media Text</title><link>https://deboranozza.com/publication/2022-xlmemo-multilingual-emotion-prediction/</link><pubDate>Tue, 12 Apr 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-xlmemo-multilingual-emotion-prediction/</guid><description/></item><item><title>Exposing the limits of Zero-shot Cross-lingual Hate Speech Detection</title><link>https://deboranozza.com/publication/2021-zeroshot-crosslingual-hate-speech/</link><pubDate>Mon, 02 Aug 2021 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2021-zeroshot-crosslingual-hate-speech/</guid><description/></item><item><title>HONEST: Measuring Hurtful Sentence Completion in Language Models</title><link>https://deboranozza.com/publication/2021-honest-hurtful-language-model/</link><pubDate>Sun, 06 Jun 2021 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2021-honest-hurtful-language-model/</guid><description/></item><item><title>LearningToAdapt with word embeddings: Domain adaptation of Named Entity Recognition systems</title><link>https://deboranozza.com/publication/2021_learningtoadapt/</link><pubDate>Sun, 06 Jun 2021 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2021_learningtoadapt/</guid><description/></item><item><title>FEEL-IT: Emotion and Sentiment Classification for the Italian Language</title><link>https://deboranozza.com/publication/2021-feelit-italian-sentiment-emotion/</link><pubDate>Sun, 16 May 2021 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2021-feelit-italian-sentiment-emotion/</guid><description/></item><item><title>MilaNLP @ WASSA: Does BERT Feel Sad When You Cry?</title><link>https://deboranozza.com/publication/2021-wassa-emotion-multitask/</link><pubDate>Sun, 16 May 2021 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2021-wassa-emotion-multitask/</guid><description/></item><item><title>Cross-lingual Contextualized Topic Models with Zero-shot Learning</title><link>https://deboranozza.com/publication/2021-crosslingual-topic-model/</link><pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2021-crosslingual-topic-model/</guid><description/></item><item><title>AMI @ EVALITA2020: Automatic Misogyny Identification</title><link>https://deboranozza.com/publication/2020_automatic_misogyny_identification/</link><pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2020_automatic_misogyny_identification/</guid><description/></item><item><title>Which Matters Most? Comparing the Impact of Concept and Document Relationships in Topic Models</title><link>https://deboranozza.com/publication/2020_concept_document_topic_models/</link><pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2020_concept_document_topic_models/</guid><description/></item><item><title>Profiling Italian Misogynist: An Empirical Study</title><link>https://deboranozza.com/publication/2020_profiling_italian_misogynist/</link><pubDate>Thu, 02 Apr 2020 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2020_profiling_italian_misogynist/</guid><description/></item><item><title>What the [MASK]? Making Sense of Language-Specific BERT Models</title><link>https://deboranozza.com/publication/2020_bertlang/</link><pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2020_bertlang/</guid><description/></item><item><title>CAGE: Constrained deep Attributed Graph Embedding</title><link>https://deboranozza.com/publication/2019_cage/</link><pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2019_cage/</guid><description/></item><item><title>Hate Speech and Misogyny Detection</title><link>https://deboranozza.com/project/hate_speech_misogyny_detection/</link><pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate><guid>https://deboranozza.com/project/hate_speech_misogyny_detection/</guid><description>&lt;p>While the exponential growth of &lt;strong>Social Media&lt;/strong> such as Twitter and Facebook has permit people to freely express themselves in various forms (text, video, images), these new sources of communication, where anonymity or pseudo-anonymity enables the possibility to afflict a target without being recognized or traced, has led to an increasing propagation of hate speech. Automatic Machine Learning models for the detection of &lt;strong>Hate Speech&lt;/strong> could help in preventing or automatically reporting these misbehaviors and consequently reduce the episodes of misogyny, racism, homophobia and cyberbullying. This could be helpful both for protecting individuals’ health and also to monitor public reactions to events.&lt;/p>
&lt;p>In order to provide a benchmark dataset for &lt;strong>Hate Speech&lt;/strong> and &lt;strong>Misogyny Detection&lt;/strong>, I have contributed to the organization of the &lt;a href="https://dnozza.github.io/publication/2018_automatic_misogyny_identification/">Automatic Misogyny Identification(AMI) shared task at Evalita 2018&lt;/a> and &lt;a href="https://dnozza.github.io/publication/2020_automatic_misogyny_identification/">2020&lt;/a> in Italian and English language and of the &lt;a href="https://dnozza.github.io/publication/2019_semeval_hateval/">HatEval task at SemEval 2019&lt;/a> about the detection of hate speech against immigrants and women in Spanish and English messages extracted from Twitter.&lt;/p>
&lt;p>&lt;em>These tasks permit to create and share the first labelled corpora for misogyny detection in Spanish and Italian. I firmly believe that we still have a long way to go: there are 3,909 written languages in the world, most without misogyny data sets. Moreover, we need to assure that data collection methodologies are the same across all languages in order for them to be valuable.&lt;/em> 🌎🌍🌏&lt;/p>
&lt;p>In my paper at ACL 2021, I demonstrated that &lt;a href="https://dnozza.github.io/publication/2021-zeroshot-crosslingual-hate-speech/">zero-shot, cross-lingual transfer learning framework, in its traditional settings, is not a feasible solution for solving the lack of models and labeled corpora for hate speech detection&lt;/a>. Limits are related to the high presence of language- and target-specific taboo interjections in non-hateful contexts, like porca puttana in Italian or puta in Spanish.
&lt;em>I argue that hate speech is &lt;strong>language specific&lt;/strong>, and NLP approaches to identifying hate speech must account for that specificity.&lt;/em> 🔍&lt;/p>
&lt;p>Further limitations of creating hate speech detection models can be found on popularly employed pretrained language models. Indeed, in my paper presented at NAACL 2021, I show that &lt;a href="https://dnozza.github.io/publication/2021-honest-hurtful-language-model/">4.3% of the time language models complete a sentence with a hurtful word (sentence completions refer to sexual promiscuity when the target is female in 9% of the time, and in 4% to homosexuality when the target is male)&lt;/a>⚠️. When the subjects belong to the LGBTQIA+ community, the problem is even higher: &lt;a href="https://dnozza.github.io/publication/2022-honest-hurtful-language-model-lgbtqia+/">the most likely LLM-generated completion is an identity attack 13% of the time&lt;/a> (published at LT-EDI workshop at ACL 2022). For sistematicaly measure this issue, we propose &lt;a href="https://github.com/MilaNLProc/honest">HONEST&lt;/a> a score to measure hurtful sentence completions in any language models.&lt;/p>
&lt;p>In my work presented at International Conference on Web Intelligence (WI &amp;lsquo;19), I made some additional investigation on the &lt;a href="https://dnozza.github.io/publication/2021-zeroshot-crosslingual-hate-speech/">presence of unintended bias in machine learning models for &lt;strong>Misogyny Detection&lt;/strong>&lt;/a>. This can lead the models to recognize positive or neutral texts as hate speech texts only because it contains certain terms (e.g. woman, girl), not guaranteeing &lt;strong>fairness&lt;/strong>. &lt;em>Can you imagine seeing &amp;ldquo;You&amp;rsquo;re a smart woman&amp;rdquo; predicted as misogynous just because it&amp;rsquo;s talking about women?&lt;/em> 🤦‍♀️
&lt;a href="https://dnozza.github.io/publication/2022-interpretability-transformer-mysogyny-detection/">Exploring post-hoc interpretability models for misogyny detection&lt;/a>, further demonstrated this problem. Models (like BERT) are paying too much attention to words that do not carry misogynous meaning (e.g. woman) (published at NLP-Power workshop at ACL 2022).&lt;/p>
&lt;p>In my recent paper at ACL 2022 findings, we introduce a novel technique to exactly counteract this issue of unintended bias. We propose &lt;a href="https://dnozza.github.io/publication/2022-entropy-attention-regularization-bias/">Entropy-based Attention Regularization (EAR 👂)&lt;/a> to discourage overfitting to training-specific terms of Transformer-based models (e.g., BERT). The resulting model matches or exceeds state-of-the-art performance for hate speech classification and bias metrics on three benchmark corpora in English and Italian&lt;/p>
&lt;p>🎙️🎙️ Check out my latest &lt;strong>interview&lt;/strong> on &lt;a href="https://www.youtube.com/watch?v=kU8zvmifyHE&amp;amp;t=3s">Ethics and bias in Artificial Intelligence&lt;/a>!!&lt;/p></description></item><item><title>Unintended Bias in Misogyny Detection</title><link>https://deboranozza.com/publication/2019_unintended_bias_misogyny_detection/</link><pubDate>Mon, 14 Oct 2019 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2019_unintended_bias_misogyny_detection/</guid><description/></item><item><title>Word Embeddings for Unsupervised Named Entity Linking</title><link>https://deboranozza.com/publication/2019_word_embeddings_named_entity_linking/</link><pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2019_word_embeddings_named_entity_linking/</guid><description/></item><item><title>SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter</title><link>https://deboranozza.com/publication/2019_semeval_hateval/</link><pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2019_semeval_hateval/</guid><description/></item><item><title>Overview of the Evalita 2018 Task on Automatic Misogyny Identification (AMI)</title><link>https://deboranozza.com/publication/2018_automatic_misogyny_identification/</link><pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2018_automatic_misogyny_identification/</guid><description/></item><item><title>Mapping Natural Language Labels to Structured Web Resources</title><link>https://deboranozza.com/publication/2018_mapping_labels_web_resources/</link><pubDate>Thu, 01 Nov 2018 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2018_mapping_labels_web_resources/</guid><description/></item><item><title>Towards encoding time in text-based entity embeddings</title><link>https://deboranozza.com/publication/2018_encoding_time_entity_embeddings/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2018_encoding_time_entity_embeddings/</guid><description/></item><item><title>UNIMIB@ NEEL-IT: Named Entity Recognition and Linking of Italian Tweets</title><link>https://deboranozza.com/publication/2016_named_entity_linking_italian_tweets/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2016_named_entity_linking_italian_tweets/</guid><description/></item><item><title>Adapting Named Entity Types to New Ontologies in a Microblogging Environment</title><link>https://deboranozza.com/publication/2018_adapting_named_entity_types/</link><pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2018_adapting_named_entity_types/</guid><description/></item><item><title>A Multi-View Sentiment Corpus</title><link>https://deboranozza.com/publication/2017_multiview_sentiment_corpus/</link><pubDate>Sat, 01 Apr 2017 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2017_multiview_sentiment_corpus/</guid><description/></item><item><title>Towards adaptation of named entity classification</title><link>https://deboranozza.com/publication/2017_adaptation_entity_types/</link><pubDate>Sat, 01 Apr 2017 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2017_adaptation_entity_types/</guid><description/></item><item><title>TWINE: A real-time system for TWeet analysis via INformation Extraction</title><link>https://deboranozza.com/publication/2017_twine/</link><pubDate>Sat, 01 Apr 2017 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2017_twine/</guid><description/></item><item><title>Deep learning and ensemble methods for Domain Adaptation</title><link>https://deboranozza.com/publication/2016_deep_learning_sentiment_domain_adaptation/</link><pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2016_deep_learning_sentiment_domain_adaptation/</guid><description/></item><item><title>Unsupervised Irony Detection: A Probabilistic Model with Word Embeddings</title><link>https://deboranozza.com/publication/2016_unsupervised_irony_detection/</link><pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2016_unsupervised_irony_detection/</guid><description/></item><item><title>A latent representation model for sentiment analysis in heterogeneous social networks</title><link>https://deboranozza.com/publication/2014_latent_representation_sentiment_analysis_social_network/</link><pubDate>Sun, 01 Feb 2015 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2014_latent_representation_sentiment_analysis_social_network/</guid><description/></item></channel></rss>