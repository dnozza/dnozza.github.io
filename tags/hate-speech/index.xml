<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>hate speech on Debora Nozza</title><link>https://deboranozza.com/tags/hate-speech/</link><description>Recent content in hate speech on Debora Nozza</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>&amp;copy; Debora Nozza, {year}</copyright><lastBuildDate>Wed, 12 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://deboranozza.com/tags/hate-speech/index.xml" rel="self" type="application/rss+xml"/><item><title>MilaNLP at SemEval-2023 Task 10: Ensembling Domain-Adapted and Regularized Pretrained Language Models for Robust Sexism Detection</title><link>https://deboranozza.com/publication/2023-milanlp-semeval-2023-task-10-ensembling-domain-adapted-regularized-pretrained-language-models-robust-sexism-detection/</link><pubDate>Wed, 12 Jul 2023 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2023-milanlp-semeval-2023-task-10-ensembling-domain-adapted-regularized-pretrained-language-models-robust-sexism-detection/</guid><description/></item><item><title>Respectful or Toxic? Using Zero-Shot Learning with Language Models to Detect Hate Speech</title><link>https://deboranozza.com/publication/2023-zero-shot-prompting-hate-speech/</link><pubDate>Wed, 12 Jul 2023 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2023-zero-shot-prompting-hate-speech/</guid><description/></item><item><title>The State of Profanity Obfuscation in Natural Language Processing Scientific Publications</title><link>https://deboranozza.com/publication/2023-prof-profanity-obfuscation-nlp/</link><pubDate>Wed, 12 Jul 2023 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2023-prof-profanity-obfuscation-nlp/</guid><description/></item><item><title>A Cross-Lingual Study of Homotransphobia on Twitter</title><link>https://deboranozza.com/publication/2023-cross-lingual-study-homotransphobia/</link><pubDate>Fri, 12 May 2023 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2023-cross-lingual-study-homotransphobia/</guid><description/></item><item><title>Measuring Harmful Representations in Scandinavian Language Models</title><link>https://deboranozza.com/publication/2022-honest-harmful-scandinavian-language-model/</link><pubDate>Fri, 09 Dec 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-honest-harmful-scandinavian-language-model/</guid><description/></item><item><title>Data-Efficient Strategies for Expanding Hate Speech Detection into Under-Resourced Languages</title><link>https://deboranozza.com/publication/2022-strategies-hate-speech-detection-under-resourced-languages/</link><pubDate>Thu, 20 Oct 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-strategies-hate-speech-detection-under-resourced-languages/</guid><description/></item><item><title>The State of Profanity Obfuscation in Natural Language Processing Scientific Publications</title><link>https://deboranozza.com/publication/2022-prof-profanity-obfuscation-nlp/</link><pubDate>Fri, 14 Oct 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-prof-profanity-obfuscation-nlp/</guid><description/></item><item><title>HATE-ITA: Hate Speech Detection in Italian Social Media Text</title><link>https://deboranozza.com/publication/2022-hate-speech-detection-italian-social-media/</link><pubDate>Tue, 12 Jul 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-hate-speech-detection-italian-social-media/</guid><description/></item><item><title>Multilingual HateCheck: Functional Tests for Multilingual Hate Speech Detection Models</title><link>https://deboranozza.com/publication/2022-multilingual-hatecheck-hate-speech-functional-tests/</link><pubDate>Tue, 12 Jul 2022 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2022-multilingual-hatecheck-hate-speech-functional-tests/</guid><description/></item><item><title>Exposing the limits of Zero-shot Cross-lingual Hate Speech Detection</title><link>https://deboranozza.com/publication/2021-zeroshot-crosslingual-hate-speech/</link><pubDate>Mon, 02 Aug 2021 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2021-zeroshot-crosslingual-hate-speech/</guid><description/></item><item><title>HONEST: Measuring Hurtful Sentence Completion in Language Models</title><link>https://deboranozza.com/publication/2021-honest-hurtful-language-model/</link><pubDate>Sun, 06 Jun 2021 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2021-honest-hurtful-language-model/</guid><description/></item><item><title>AMI @ EVALITA2020: Automatic Misogyny Identification</title><link>https://deboranozza.com/publication/2020_automatic_misogyny_identification/</link><pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2020_automatic_misogyny_identification/</guid><description/></item><item><title>Profiling Italian Misogynist: An Empirical Study</title><link>https://deboranozza.com/publication/2020_profiling_italian_misogynist/</link><pubDate>Thu, 02 Apr 2020 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2020_profiling_italian_misogynist/</guid><description/></item><item><title>Hate Speech and Misogyny Detection</title><link>https://deboranozza.com/project/hate_speech_misogyny_detection/</link><pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate><guid>https://deboranozza.com/project/hate_speech_misogyny_detection/</guid><description>&lt;p>While the exponential growth of &lt;strong>Social Media&lt;/strong> such as Twitter and Facebook has permit people to freely express themselves in various forms (text, video, images), these new sources of communication, where anonymity or pseudo-anonymity enables the possibility to afflict a target without being recognized or traced, has led to an increasing propagation of hate speech. Automatic Machine Learning models for the detection of &lt;strong>Hate Speech&lt;/strong> could help in preventing or automatically reporting these misbehaviors and consequently reduce the episodes of misogyny, racism, homophobia and cyberbullying. This could be helpful both for protecting individuals‚Äô health and also to monitor public reactions to events.&lt;/p>
&lt;p>In order to provide a benchmark dataset for &lt;strong>Hate Speech&lt;/strong> and &lt;strong>Misogyny Detection&lt;/strong>, I have contributed to the organization of the &lt;a href="https://dnozza.github.io/publication/2018_automatic_misogyny_identification/">Automatic Misogyny Identification(AMI) shared task at Evalita 2018&lt;/a> and &lt;a href="https://dnozza.github.io/publication/2020_automatic_misogyny_identification/">2020&lt;/a> in Italian and English language and of the &lt;a href="https://dnozza.github.io/publication/2019_semeval_hateval/">HatEval task at SemEval 2019&lt;/a> about the detection of hate speech against immigrants and women in Spanish and English messages extracted from Twitter.&lt;/p>
&lt;p>&lt;em>These tasks permit to create and share the first labelled corpora for misogyny detection in Spanish and Italian. I firmly believe that we still have a long way to go: there are 3,909 written languages in the world, most without misogyny data sets. Moreover, we need to assure that data collection methodologies are the same across all languages in order for them to be valuable.&lt;/em> üåéüåçüåè&lt;/p>
&lt;p>In my paper at ACL 2021, I demonstrated that &lt;a href="https://dnozza.github.io/publication/2021-zeroshot-crosslingual-hate-speech/">zero-shot, cross-lingual transfer learning framework, in its traditional settings, is not a feasible solution for solving the lack of models and labeled corpora for hate speech detection&lt;/a>. Limits are related to the high presence of language- and target-specific taboo interjections in non-hateful contexts, like porca puttana in Italian or puta in Spanish.
&lt;em>I argue that hate speech is &lt;strong>language specific&lt;/strong>, and NLP approaches to identifying hate speech must account for that specificity.&lt;/em> üîç&lt;/p>
&lt;p>Further limitations of creating hate speech detection models can be found on popularly employed pretrained language models. Indeed, in my paper presented at NAACL 2021, I show that &lt;a href="https://dnozza.github.io/publication/2021-honest-hurtful-language-model/">4.3% of the time language models complete a sentence with a hurtful word (sentence completions refer to sexual promiscuity when the target is female in 9% of the time, and in 4% to homosexuality when the target is male)&lt;/a>‚ö†Ô∏è. When the subjects belong to the LGBTQIA+ community, the problem is even higher: &lt;a href="https://dnozza.github.io/publication/2022-honest-hurtful-language-model-lgbtqia+/">the most likely LLM-generated completion is an identity attack 13% of the time&lt;/a> (published at LT-EDI workshop at ACL 2022). For sistematicaly measure this issue, we propose &lt;a href="https://github.com/MilaNLProc/honest">HONEST&lt;/a> a score to measure hurtful sentence completions in any language models.&lt;/p>
&lt;p>In my work presented at International Conference on Web Intelligence (WI &amp;lsquo;19), I made some additional investigation on the &lt;a href="https://dnozza.github.io/publication/2021-zeroshot-crosslingual-hate-speech/">presence of unintended bias in machine learning models for &lt;strong>Misogyny Detection&lt;/strong>&lt;/a>. This can lead the models to recognize positive or neutral texts as hate speech texts only because it contains certain terms (e.g. woman, girl), not guaranteeing &lt;strong>fairness&lt;/strong>. &lt;em>Can you imagine seeing &amp;ldquo;You&amp;rsquo;re a smart woman&amp;rdquo; predicted as misogynous just because it&amp;rsquo;s talking about women?&lt;/em> ü§¶‚Äç‚ôÄÔ∏è
&lt;a href="https://dnozza.github.io/publication/2022-interpretability-transformer-mysogyny-detection/">Exploring post-hoc interpretability models for misogyny detection&lt;/a>, further demonstrated this problem. Models (like BERT) are paying too much attention to words that do not carry misogynous meaning (e.g. woman) (published at NLP-Power workshop at ACL 2022).&lt;/p>
&lt;p>In my recent paper at ACL 2022 findings, we introduce a novel technique to exactly counteract this issue of unintended bias. We propose &lt;a href="https://dnozza.github.io/publication/2022-entropy-attention-regularization-bias/">Entropy-based Attention Regularization (EAR üëÇ)&lt;/a> to discourage overfitting to training-specific terms of Transformer-based models (e.g., BERT). The resulting model matches or exceeds state-of-the-art performance for hate speech classification and bias metrics on three benchmark corpora in English and Italian&lt;/p>
&lt;p>üéôÔ∏èüéôÔ∏è Check out my latest &lt;strong>interview&lt;/strong> on &lt;a href="https://www.youtube.com/watch?v=kU8zvmifyHE&amp;amp;t=3s">Ethics and bias in Artificial Intelligence&lt;/a>!!&lt;/p></description></item><item><title>Unintended Bias in Misogyny Detection</title><link>https://deboranozza.com/publication/2019_unintended_bias_misogyny_detection/</link><pubDate>Mon, 14 Oct 2019 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2019_unintended_bias_misogyny_detection/</guid><description/></item><item><title>SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter</title><link>https://deboranozza.com/publication/2019_semeval_hateval/</link><pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2019_semeval_hateval/</guid><description/></item><item><title>Overview of the Evalita 2018 Task on Automatic Misogyny Identification (AMI)</title><link>https://deboranozza.com/publication/2018_automatic_misogyny_identification/</link><pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate><guid>https://deboranozza.com/publication/2018_automatic_misogyny_identification/</guid><description/></item></channel></rss>